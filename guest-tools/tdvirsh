#!/bin/bash
################################################################################
# tdvirsh - Trust Domain Virtual Machine Manager with Storage Pools
################################################################################
#
# A production-ready wrapper around virsh for managing Intel TDX Trust Domains
# with integrated libvirt storage pool support and runtime user configuration.
#
# FEATURES:
#   - Automatic storage pool creation and management
#   - Base image auto-import to pool
#   - Copy-on-write overlay volumes
#   - Runtime user configuration injection via cloud-init
#   - GPU passthrough with VFIO setup
#   - Rich VM information display (IP, SSH port, vSOCK CID)
#   - Graceful VM shutdown
#   - Orphan volume detection and cleanup
#   - Virsh command passthrough
#
# USAGE:
#   ./tdvirsh new --user alice --ssh-key ~/.ssh/id_rsa.pub
#   ./tdvirsh list
#   ./tdvirsh delete <domain|all>
#   ./tdvirsh pool-info
#   ./tdvirsh pool-cleanup
#
################################################################################

# This file is part of Canonical's TDX repository which includes tools
# to setup and configure a confidential computing environment
# based on Intel TDX technology.
# See the LICENSE file in the repository for the license text.

# Copyright 2024 Canonical Ltd.
# SPDX-License-Identifier: GPL-3.0-only

# This program is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License version 3,
# as published by the Free Software Foundation.
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranties
# of MERCHANTABILITY, SATISFACTORY QUALITY, or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU General Public License for more details.

################################################################################
# GLOBAL CONSTANTS
################################################################################

# Domain prefix for all TDs created by this script
# Used for filtering and identification
DOMAIN_PREFIX="tdvirsh"

# Script location (resolved to absolute path)
# Used for locating templates and other resources
SCRIPT_DIR=$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)

# Script name (for error messages)
SCRIPT_NAME=$(basename "$0")

# Ubuntu version detection (e.g., "24.04")
# Used for auto-detecting default image names
UBUNTU_VERSION=$(lsb_release -rs)

# Default base image path
# Constructed from Ubuntu version for automatic discovery
# Example: ./image/tdx-guest-ubuntu-24.04-generic.qcow2
BASE_IMG_DEFAULT=${SCRIPT_DIR}/image/tdx-guest-ubuntu-${UBUNTU_VERSION}-generic.qcow2

# Default libvirt XML template
# Contains VM configuration (CPU, memory, devices, etc.)
XML_TEMPLATE_DEFAULT=${SCRIPT_DIR}/trust_domain.xml.template

################################################################################
# STORAGE POOL CONFIGURATION
################################################################################

# Libvirt storage pool name
# This pool manages all base images and overlay volumes
STORAGE_POOL_NAME="libvirt-pool"

# Storage pool directory path
# Standard libvirt location for images
# Automatically created if doesn't exist
STORAGE_POOL_PATH="/var/lib/libvirt/images"

# Working directory for XML files
# Set to pool path to keep everything in one location
WORKDIR_PATH="${STORAGE_POOL_PATH}"

################################################################################
# GLOBAL VARIABLES
################################################################################

# Overlay image full path (set during overlay creation)
# Example: /var/lib/libvirt/images/overlay.AbC123XyZ456789.qcow2
overlay_image_path=""

# Overlay image name only (for pool operations)
# Example: overlay.AbC123XyZ456789.qcow2
overlay_image_name=""

# Base image path (resolved to absolute path from default or user-provided)
base_img_path=$(realpath ${BASE_IMG_DEFAULT})

# XML template path (resolved to absolute path)
xml_template_path=$(realpath ${XML_TEMPLATE_DEFAULT})

# Created domain name (set after VM creation)
# Example: tdvirsh-trust_domain-abc123-def456-...
created_domain=""

# User configuration variables (for runtime user injection)
guest_user=""
ssh_key_path=""
guest_password=""
guest_hostname="tdx-guest"
cidata_iso_path=""

################################################################################
# CONFIGURATION FILE SOURCING
################################################################################

# Source external configuration file if present
# This allows users to set environment variables like:
#   - GUEST_USER
#   - GUEST_PASSWORD
#   - GUEST_HOSTNAME
#   - TDX_SETUP_INTEL_KERNEL
# The config file is expected two directories up from script location
if [ -f ${SCRIPT_DIR}/../../setup-tdx-config ]; then
    source ${SCRIPT_DIR}/../../setup-tdx-config
fi

################################################################################
# FUNCTION: usage
# Display help message with all available commands and options
################################################################################
usage() {
    cat <<EOM
Usage: ./$(basename "${BASH_SOURCE[0]}") [-h] [COMMAND] [OPTIONS]

Manage Trust Domains (TDs) using libvirt with storage pool integration and
runtime user configuration.

Available commands:

new [OPTIONS]               Create and run a new Trust Domain (TD)
    --td-image|-i PATH        TD image path (default: ./image/tdx-guest-ubuntu-${UBUNTU_VERSION}-generic.qcow2)
    --xml-template|-t PATH    XML template path (default: ./trust_domain.xml.template)
    --pool POOL_NAME          Storage pool name (default: libvirt-pool)
    --user|-u USERNAME        Guest username (REQUIRED)
    --ssh-key|-k PATH         SSH public key file (recommended)
    --password|-p PASSWORD    Guest password (alternative to SSH key)
    --hostname|-n HOSTNAME    Guest hostname (default: tdx-guest)
    --gpus|-g BDF_LIST        GPUs to pass-through

delete <domain|all>         Stop and delete Trust Domain (TD)
                                <domain>: Valid domain name
                                <all>: Delete all ${DOMAIN_PREFIX} VMs and their overlay volumes

list                        List all VMs with connection details (IP, SSH port, vSOCK CID)

pool-info                   Show storage pool information and list all volumes

pool-cleanup                Remove orphaned overlay volumes no longer used by any domain

-h, --help                  Print this help and exit

Storage Pool:
  Name: ${STORAGE_POOL_NAME}
  Path: ${STORAGE_POOL_PATH}
  Note: Pool is automatically created if it doesn't exist
        Images are automatically imported to storage pool

All other options will be passed to virsh. To see virsh usage run:
    virsh --help

Examples:
  # Create new TD with user alice and SSH key (recommended)
  ./$(basename "${BASH_SOURCE[0]}") new --user alice --ssh-key ~/.ssh/id_rsa.pub

  # Create TD with custom image and hostname
  ./$(basename "${BASH_SOURCE[0]}") new -i /path/to/image.qcow2 -u bob -k ~/.ssh/id_ed25519.pub -n bob-td

  # Create TD with GPU passthrough
  ./$(basename "${BASH_SOURCE[0]}") new -u charlie -k ~/.ssh/id_rsa.pub -g 0000:17:00.0,0000:65:00.0

  # Create TD with custom storage pool
  ./$(basename "${BASH_SOURCE[0]}") new -u dave -k ~/.ssh/id_rsa.pub --pool my-custom-pool

  # List all TDs with connection info
  ./$(basename "${BASH_SOURCE[0]}") list

  # Check storage pool status
  ./$(basename "${BASH_SOURCE[0]}") pool-info

  # Clean up orphaned overlay volumes
  ./$(basename "${BASH_SOURCE[0]}") pool-cleanup

EOM
}

################################################################################
# FUNCTION: ensure_storage_pool
#
# Ensures the libvirt storage pool exists and is active
#
# DESCRIPTION:
#   This function checks if the storage pool exists. If not, it creates the
#   pool, starts it, and sets it to auto-start on boot. If the pool exists
#   but is inactive, it starts it. Finally, it refreshes the pool to detect
#   any manually added images.
#
# GLOBALS USED:
#   STORAGE_POOL_NAME - Name of the storage pool
#   STORAGE_POOL_PATH - Directory path for the pool
#
# SIDE EFFECTS:
#   - Creates ${STORAGE_POOL_PATH} directory if needed
#   - Defines, starts, and sets autostart for libvirt pool
#   - Refreshes pool contents
#
# RETURNS:
#   0 on success
################################################################################
ensure_storage_pool() {
    # Check if pool exists by querying its info
    # Redirect errors to /dev/null to avoid cluttering output
    if ! virsh pool-info ${STORAGE_POOL_NAME} &>/dev/null; then
        echo "Creating storage pool '${STORAGE_POOL_NAME}' at ${STORAGE_POOL_PATH}..."

        # Create the target directory if it doesn't exist
        # Requires sudo since /var/lib/libvirt typically needs privileges
        sudo mkdir -p ${STORAGE_POOL_PATH}

        # Define the storage pool using libvirt API
        # Type: 'dir' (directory-based pool)
        # Target: ${STORAGE_POOL_PATH}
        virsh pool-define-as ${STORAGE_POOL_NAME} \
            dir \
            --target ${STORAGE_POOL_PATH} >/dev/null

        # Start the pool (makes it active)
        virsh pool-start ${STORAGE_POOL_NAME} >/dev/null

        # Set pool to start automatically on system boot
        virsh pool-autostart ${STORAGE_POOL_NAME} >/dev/null

        echo "Storage pool '${STORAGE_POOL_NAME}' created successfully."
    fi

    # Ensure pool is active (running state)
    # Extract the "State:" line from pool-info and check if it's "running"
    if [[ "$(virsh pool-info ${STORAGE_POOL_NAME} | awk '/State:/ {print $2}')" != "running" ]]; then
        echo "Starting storage pool '${STORAGE_POOL_NAME}'..."
        virsh pool-start ${STORAGE_POOL_NAME} >/dev/null
    fi

    # Refresh pool to detect any volumes that were manually added to the directory
    # This synchronizes libvirt's internal state with the filesystem
    virsh pool-refresh ${STORAGE_POOL_NAME} >/dev/null
}

################################################################################
# FUNCTION: import_base_image_to_pool
#
# Imports a base image into the storage pool if not already present
#
# DESCRIPTION:
#   Checks if the base image exists in the storage pool. If not, copies it
#   from the filesystem to the pool directory with proper permissions.
#
# GLOBALS USED:
#   base_img_path - Full path to base image
#   STORAGE_POOL_NAME - Name of storage pool
#   STORAGE_POOL_PATH - Directory path for pool
#
# RETURNS:
#   0 if image already exists or was successfully imported
#   1 if source image not found
#
# SIDE EFFECTS:
#   - Copies image file to pool directory
#   - Sets ownership to root:root
#   - Sets permissions to 644
#   - Refreshes pool to register new volume
################################################################################
import_base_image_to_pool() {
    # Extract just the filename from the full path
    local base_img_name=$(basename ${base_img_path})

    # Check if the base image already exists as a volume in the pool
    # If yes, skip import to avoid unnecessary copy
    if virsh vol-info --pool ${STORAGE_POOL_NAME} ${base_img_name} &>/dev/null; then
        echo "Base image '${base_img_name}' already exists in storage pool."
        return 0
    fi

    # Verify the source image file exists
    if [[ ! -f ${base_img_path} ]]; then
        echo "ERROR: Base image not found at ${base_img_path}"
        return 1
    fi

    echo "Importing base image to storage pool..."

    # Copy the image file to the pool directory
    # Using sudo because pool directory is typically owned by root
    sudo cp ${base_img_path} ${STORAGE_POOL_PATH}/${base_img_name}

    # Set proper ownership for libvirt access
    # Base image is read-only, owned by root but accessible by qemu group
    # This is more secure than world-readable (644)
    sudo chown root:qemu ${STORAGE_POOL_PATH}/${base_img_name}

    # Set read permissions for owner and group only (not world-readable)
    # Owner (root): read/write, Group (qemu): read, Others: none
    sudo chmod 640 ${STORAGE_POOL_PATH}/${base_img_name}

    # Refresh the pool so libvirt detects the new volume
    # Without this, virsh vol-list wouldn't show the new image
    virsh pool-refresh ${STORAGE_POOL_NAME} >/dev/null

    echo "Base image imported successfully."
}

################################################################################
# FUNCTION: attach_gpus
#
# Main entry point for GPU attachment
#
# PARAMETERS:
#   $1 - Comma-separated list of GPU BDF addresses (e.g., "0000:17:00.0,0000:65:00.0")
#
# DESCRIPTION:
#   Coordinates GPU preparation and XML generation for passthrough
#
# GLOBALS SET:
#   HOSTDEVS - XML fragment for GPU devices
################################################################################
attach_gpus() {
    # If no GPUs specified, return early
    if [ -z "$1" ]; then
	return
    fi

    # Prepare GPUs for VFIO passthrough
    prepare_gpus "$1"

    # Generate XML for GPU devices
    build_hostdevs_xml "$1"
}

################################################################################
# FUNCTION: prepare_gpus
#
# Prepares GPUs for VFIO passthrough
#
# PARAMETERS:
#   $1 - Comma-separated list of GPU BDF addresses
#
# DESCRIPTION:
#   Calls external setup script to unbind GPUs from host driver and bind to
#   vfio-pci. Also increases DMA entry limit for large memory allocations.
#
# SIDE EFFECTS:
#   - Unbinds GPUs from host driver
#   - Binds GPUs to vfio-pci
#   - Increases VFIO IOMMU DMA entry limit to 0x200000 (2097152)
#
# NOTES:
#   - Requires sudo privileges
#   - setup-gpus.sh should exist at ../gpu-cc/h100/setup-gpus.sh
#   - DMA limit increase prevents VFIO errors with GPU memory allocation
################################################################################
prepare_gpus() {
    # Call external GPU setup script
    # This script unbinds GPUs from host drivers and binds to vfio-pci
    # Output suppressed to keep console clean
    sudo ${SCRIPT_DIR}/../gpu-cc/h100/setup-gpus.sh "$1" &> /dev/null

    # Increase the VFIO IOMMU DMA entry limit
    # Default is often too low for GPU passthrough with large memory
    # 0x200000 (2,097,152) entries should be sufficient for most GPU workloads
    echo 0x200000 | sudo tee /sys/module/vfio_iommu_type1/parameters/dma_entry_limit >/dev/null
}

################################################################################
# FUNCTION: build_hostdevs_xml
#
# Generates libvirt XML for GPU passthrough devices
#
# PARAMETERS:
#   $1 - Comma-separated list of GPU BDF addresses
#
# DESCRIPTION:
#   Parses BDF addresses, validates format using regex, and generates
#   libvirt <hostdev> XML fragments for each GPU.
#
# BDF FORMAT:
#   0000:00:00.0
#   ^^^^:^^:^^.^
#   │    │  │  └─ Function (0-7)
#   │    │  └──── Slot (00-1F hex)
#   │    └─────── Bus (00-FF hex)
#   └──────────── Domain (0000-FFFF hex)
#
# GLOBALS SET:
#   HOSTDEVS - XML fragment containing all GPU hostdev entries
#
# EXAMPLE OUTPUT:
#   <hostdev mode='subsystem' type='pci' managed='yes'>
#     <source>
#       <address domain='0x0000' bus='0x17' slot='0x00' function='0x0'/>
#     </source>
#   </hostdev>
################################################################################
build_hostdevs_xml() {
    local pci_list="$1"

    # Split comma-separated BDF list into array
    # IFS (Internal Field Separator) temporarily set to comma
    IFS=',' read -ra bdfs <<< "$pci_list"

    # Process each BDF address
    for bdf in "${bdfs[@]}"; do
        # Validate BDF format using regex
        # Pattern: 4-digit domain : 2-digit bus : 2-digit slot . 1-digit function
        # Example match: 0000:17:00.0
        if [[ "$bdf" =~ ^([0-9a-fA-F]{4}):([0-9a-fA-F]{2}):([0-9a-fA-F]{2})\.([0-7])$ ]]; then
            # Extract components using BASH_REMATCH array
            # BASH_REMATCH[0] = full match
            # BASH_REMATCH[1] = domain
            # BASH_REMATCH[2] = bus
            # BASH_REMATCH[3] = slot
            # BASH_REMATCH[4] = function
            domain="${BASH_REMATCH[1]}"
            bus="${BASH_REMATCH[2]}"
            slot="${BASH_REMATCH[3]}"
            func="${BASH_REMATCH[4]}"

            # Generate XML for this GPU using heredoc
            # mode='subsystem': PCI passthrough mode
            # type='pci': PCI device
            # managed='yes': Libvirt manages driver binding/unbinding
	    read -r -d '' hostdev << EOM
<hostdev mode='subsystem' type='pci' managed='yes'>
  <source>
      <address domain='${domain}' bus='0x${bus}' slot='0x${slot}' function='0x${func}'/>
  </source>
</hostdev>
EOM
            # Append to global HOSTDEVS variable (with newline)
	    HOSTDEVS="${HOSTDEVS}\n${hostdev}"
        else
            # BDF format invalid, warn user but continue
            # This allows other valid GPUs to be processed
            echo "Invalid BDF format: $bdf"
        fi
    done
}

################################################################################
# FUNCTION: check_input_paths
#
# Validates that required files exist and are accessible
#
# DESCRIPTION:
#   Checks for base image in pool or filesystem, and verifies XML template
#   exists. Exits with error if validation fails.
#
# GLOBALS USED:
#   base_img_path - Path to base image
#   xml_template_path - Path to XML template
#   STORAGE_POOL_NAME - Name of storage pool
#
# EXIT CODES:
#   1 if validation fails
#
# SIDE EFFECTS:
#   Prints informational messages about image location
################################################################################
check_input_paths() {
    error=0
    local base_img_name=$(basename ${base_img_path})

    # Check if base image exists in storage pool first
    # This avoids unnecessary filesystem checks if already imported
    if ! virsh vol-info --pool ${STORAGE_POOL_NAME} ${base_img_name} &>/dev/null; then
        # Not in pool, check filesystem
        if [ ! -f ${base_img_path} ]; then
            # Not in pool or filesystem - ERROR
            echo "TD image not found at path '${base_img_path}' or in storage pool."
            echo "Set TD image path via command line option."
            error=1
        else
            # In filesystem but not pool - will be imported
            echo "Base image found at ${base_img_path}, will import to storage pool."
        fi
    else
        # Already in pool - use it
        echo "Using base image '${base_img_name}' from storage pool."
    fi

    # Validate XML template exists
    # Template is always loaded from filesystem (not pool)
    if [ $? -ne 0 ] || [ ! -f ${xml_template_path} ]; then
        echo "libvirt guest XML template not found at path '${xml_template_path}'."
        echo "Set libvirt guest XML template path via command line option."
        error=1
    fi

    # Exit if any errors encountered
    if [ $error -ne 0 ]; then
        exit 1
    fi
}

################################################################################
# FUNCTION: generate_cidata_iso
#
# Generates a cloud-init ISO with user configuration for runtime injection
#
# DESCRIPTION:
#   Creates a cloud-init ISO containing user-specific configuration (username,
#   SSH keys, password, hostname) using the generate-user-cidata.sh helper
#   script. The ISO is attached to the VM at boot for first-time configuration.
#
# GLOBALS USED:
#   guest_user - Username for the guest
#   ssh_key_path - Path to SSH public key file (optional)
#   guest_password - Password for the guest (optional)
#   guest_hostname - Hostname for the guest
#   SCRIPT_DIR - Script directory for locating helper script
#   WORKDIR_PATH - Output directory for ISO
#
# GLOBALS SET:
#   cidata_iso_path - Full path to generated ISO file
#
# EXIT CODES:
#   1 if ISO generation fails
#
# NOTES:
#   - At least one auth method (SSH key or password) must be provided
#   - ISO filename: cidata.<15-random-chars>.iso
################################################################################
generate_cidata_iso() {
    # Generate random 15-character string for unique ISO name
    local rand_str=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c15)
    mkdir -p $WORKDIR_PATH || true
    cidata_iso_path=${WORKDIR_PATH}/cidata.${rand_str}.iso

    # Build command for cloud-init ISO generation
    local cmd="${SCRIPT_DIR}/generate-user-cidata.sh -o ${cidata_iso_path} -u ${guest_user} -n ${guest_hostname}"

    # Add SSH key if provided
    if [ -n "${ssh_key_path}" ]; then
        cmd="${cmd} -k ${ssh_key_path}"
    fi

    # Add password if provided
    if [ -n "${guest_password}" ]; then
        cmd="${cmd} -p ${guest_password}"
    fi

    # Execute cloud-init ISO generation
    if ! ${cmd}; then
        echo "ERROR: Failed to generate cloud-init ISO"
        exit 1
    fi
}

################################################################################
# FUNCTION: create_overlay_image
#
# Creates a qcow2 overlay volume in the storage pool
#
# DESCRIPTION:
#   Creates a copy-on-write overlay backed by the base image. The overlay
#   inherits size from the base and only stores differences (writes).
#
# GLOBALS USED:
#   base_img_path - Path to base image
#   STORAGE_POOL_NAME - Name of storage pool
#
# GLOBALS SET:
#   overlay_image_path - Full path to created overlay
#   overlay_image_name - Name of created overlay
#
# EXIT CODES:
#   1 if overlay creation fails
#
# NOTES:
#   - Overlay named: overlay.<15-random-chars>.qcow2
#   - Size is 0 (inherits from backing volume)
#   - Format is qcow2 (supports copy-on-write)
################################################################################
create_overlay_image() {
    # Generate random 15-character string for unique overlay name
    # Uses /dev/urandom for randomness
    # Filters to alphanumeric characters only
    local rand_str=$(head /dev/urandom | tr -dc A-Za-z0-9 | head -c15)

    # Extract base image filename
    local base_img_name=$(basename ${base_img_path})

    # Construct overlay name: overlay.<random>.qcow2
    local overlay_name="overlay.${rand_str}.qcow2"

    # Create overlay volume using libvirt storage pool API
    # This is preferred over qemu-img as it integrates with libvirt
    #
    # Parameters:
    #   ${STORAGE_POOL_NAME} - Target pool
    #   ${overlay_name} - Name for new volume
    #   0 - Size (0 means inherit from backing volume)
    #   --format qcow2 - Volume format
    #   --backing-vol ${base_img_name} - Base image to use
    #   --backing-vol-format qcow2 - Format of backing volume
    virsh vol-create-as ${STORAGE_POOL_NAME} \
        ${overlay_name} \
        0 \
        --format qcow2 \
        --backing-vol ${base_img_name} \
        --backing-vol-format qcow2 >/dev/null

    # Check if creation succeeded
    if [ $? -ne 0 ]; then
        echo "ERROR: Failed to create overlay image in storage pool."
        exit 1
    fi

    # Get the full path of the created overlay
    # virsh vol-path returns the absolute filesystem path
    overlay_image_path=$(virsh vol-path --pool ${STORAGE_POOL_NAME} ${overlay_name})

    # Store overlay name for later cleanup
    overlay_image_name=${overlay_name}

    # Set proper ownership and permissions for libvirt-qemu access
    # The overlay needs write access (unlike base image which is read-only)
    # qemu user (uid:120) and qemu group (gid:127) need access
    sudo chown qemu:qemu ${overlay_image_path}
    # Owner (qemu): read/write, Group (qemu): read, Others: none
    sudo chmod 640 ${overlay_image_path}

    echo "Created overlay volume: ${overlay_name}"
}

################################################################################
# FUNCTION: create_domain_xml
#
# Generates libvirt domain XML from template
#
# DESCRIPTION:
#   Uses AWK to perform variable substitution in the XML template:
#   - BASE_IMG_PATH -> path to base image
#   - DOMAIN -> domain prefix
#   - OVERLAY_IMG_PATH -> path to overlay image
#   - HOSTDEV_DEVICES -> GPU XML fragments (if any)
#
# GLOBALS USED:
#   base_img_path - Path to base image
#   DOMAIN_PREFIX - Prefix for domain name
#   HOSTDEVS - GPU XML fragments
#   overlay_image_path - Path to overlay
#   xml_template_path - Path to template file
#   WORKDIR_PATH - Output directory
#
# OUTPUT:
#   Creates ${WORKDIR_PATH}/${DOMAIN_PREFIX}.xml
#
# NOTES:
#   - Template must use exact variable names
#   - Output file temporarily uses DOMAIN_PREFIX.xml
#   - Later renamed to include UUID
################################################################################
create_domain_xml() {
    # Ensure output directory exists
    # || true prevents error if directory already exists
    mkdir -p ${WORKDIR_PATH} || true

    # Get base image path from storage pool
    # The base image in the pool is what libvirt-qemu needs to access
    local base_img_name=$(basename ${base_img_path})
    local base_img_pool_path="${STORAGE_POOL_PATH}/${base_img_name}"

    # Use AWK for variable substitution in template
    # AWK variables (-v flag):
    #   img_path: Base image path (from storage pool)
    #   domain: Domain prefix
    #   hostdevs: GPU XML
    #   overlay_path: Overlay path
    #   cidata_iso: Cloud-init ISO path
    #
    # gsub() function performs global substitution:
    #   gsub("PATTERN", replacement, $0)
    #   $0 represents the current line
    #
    # Process each line of template, perform substitutions, print result
    awk -v img_path=${base_img_pool_path} \
        -v domain=${DOMAIN_PREFIX} \
        -v hostdevs="${HOSTDEVS}" \
        -v overlay_path=${overlay_image_path} \
        -v cidata_iso=${cidata_iso_path} '
        {
  gsub("BASE_IMG_PATH", img_path, $0);
  gsub("DOMAIN", domain, $0);
  gsub("OVERLAY_IMG_PATH", overlay_path, $0);
  gsub("HOSTDEV_DEVICES", hostdevs, $0);
  gsub("CIDATA_ISO_PATH", cidata_iso, $0);
  print;
        }
  ' ${xml_template_path} > ${WORKDIR_PATH}/${DOMAIN_PREFIX}.xml
}

################################################################################
# FUNCTION: boot_vm
#
# Defines, renames, and starts the virtual machine
#
# DESCRIPTION:
#   1. Defines domain in libvirt from generated XML
#   2. Extracts UUID for unique naming
#   3. Renames domain to include template name and UUID
#   4. Starts the VM
#
# NAMING SCHEME:
#   ${DOMAIN_PREFIX}-${template_name}-${UUID}
#   Example: tdvirsh-trust_domain-abc123-def456-...
#
# GLOBALS USED:
#   WORKDIR_PATH - Directory containing XML
#   DOMAIN_PREFIX - Domain prefix
#   xml_template_path - Template path (for extracting name)
#
# GLOBALS SET:
#   created_domain - Full name of created domain
#
# SIDE EFFECTS:
#   - Defines domain in libvirt
#   - Renames XML file
#   - Starts VM
################################################################################
boot_vm() {
    # Define the domain from generated XML
    # This registers it with libvirt but doesn't start it yet
    virsh define ${WORKDIR_PATH}/${DOMAIN_PREFIX}.xml >/dev/null

    # Extract template filename (basename)
    # Example: /path/to/trust_domain.xml.template -> trust_domain.xml.template
    xml_template_path_fn=${xml_template_path##*/}

    # Remove .xml* extension to get template name
    # Example: trust_domain.xml.template -> trust_domain
    domain_prefix_extra=${xml_template_path_fn%.xml*}

    # If extraction failed, use default
    if [ -z "$domain_prefix_extra" ]; then
        domain_prefix_extra="td_guest"
    fi

    # Construct final domain name with UUID for uniqueness
    # Format: prefix-template-UUID
    # Example: tdvirsh-trust_domain-abc123-def456-...
    created_domain=${DOMAIN_PREFIX}-${domain_prefix_extra}-$(virsh domuuid ${DOMAIN_PREFIX})

    # Rename XML file to match final domain name
    # Suppress errors if rename fails (not critical)
    mv ${WORKDIR_PATH}/{${DOMAIN_PREFIX}.xml,${created_domain}.xml} &>/dev/null || true

    # Rename the domain in libvirt
    # This updates libvirt's internal database
    virsh domrename ${DOMAIN_PREFIX} ${created_domain} >/dev/null

    # Start the VM
    virsh start ${created_domain} >/dev/null
}

################################################################################
# FUNCTION: destroy
#
# Gracefully shuts down and deletes a Trust Domain
#
# PARAMETERS:
#   $1 - Domain name to destroy
#
# DESCRIPTION:
#   1. Verifies domain exists
#   2. Attempts graceful shutdown (5 second wait)
#   3. Forces destroy if still running
#   4. Undefines domain from libvirt
#   5. Deletes overlay volume from storage pool
#   6. Removes XML configuration file
#
# EXIT CODES:
#   1 if domain doesn't exist
#
# SIDE EFFECTS:
#   - Shuts down VM
#   - Removes domain from libvirt
#   - Deletes overlay volume
#   - Removes XML file
#
# NOTES:
#   - Always attempts graceful shutdown first for data safety
#   - Falls back to rm if pool deletion fails
################################################################################
destroy() {
    local domain_to_destroy="${1}"
    local qcow2_overlay_path
    local overlay_vol_name
    local cidata_iso_path_local

    # Sanity check: verify domain exists
    # virsh dominfo returns error if domain doesn't exist
    if ! virsh dominfo ${domain_to_destroy} &> /dev/null ; then
        echo "Problem trying to assess domain : ${domain_to_destroy}"
        exit 1
    fi

    # Extract overlay path from domain XML
    # Uses grep with Perl regex (-oP) to find overlay path
    # Looks for pattern: ${STORAGE_POOL_PATH}/overlay.*.qcow2
    qcow2_overlay_path=$(virsh dumpxml ${domain_to_destroy} | \
        grep -oP "${STORAGE_POOL_PATH}/overlay\.[A-Za-z0-9]+\.qcow2" | head -1)

    # Extract cidata ISO path from domain XML
    # Looks for pattern: ${STORAGE_POOL_PATH}/cidata.*.iso
    cidata_iso_path_local=$(virsh dumpxml ${domain_to_destroy} | \
        grep -oP "${STORAGE_POOL_PATH}/cidata\.[A-Za-z0-9]+\.iso" | head -1)

    # Extract just the filename (volume name) for pool operations
    overlay_vol_name=$(basename ${qcow2_overlay_path})

    echo "Destroying domain ${domain_to_destroy}"

    # Attempt graceful shutdown
    # Sends ACPI shutdown signal to guest OS
    # Run twice with different syntax for compatibility
    virsh shutdown ${domain_to_destroy} &>/dev/null
    virsh shutdown --domain ${domain_to_destroy} &>/dev/null

    # Wait for graceful shutdown to complete
    # 5 seconds should be enough for ACPI shutdown
    # This allows guest to:
    #   - Flush disk buffers
    #   - Unmount filesystems
    #   - Stop services cleanly
    echo "Waiting for VM to shutdown ..."
    sleep 5

    # Force destroy if still running after graceful shutdown
    # This is equivalent to pulling the power plug
    # Run twice for compatibility
    virsh destroy ${domain_to_destroy} &>/dev/null
    virsh destroy --domain ${domain_to_destroy} &>/dev/null

    # Undefine the domain (remove from libvirt)
    # This doesn't delete files, just removes registration
    virsh undefine ${domain_to_destroy} &>/dev/null

    # Delete overlay volume from storage pool
    if [[ -n "${overlay_vol_name}" ]]; then
        echo "Removing overlay volume: ${overlay_vol_name}"

        # Try pool deletion first (preferred method)
        virsh vol-delete --pool ${STORAGE_POOL_NAME} ${overlay_vol_name} &>/dev/null

        # Check if pool deletion succeeded
        if [ $? -ne 0 ]; then
            # Pool deletion failed, fall back to manual file removal
            # This can happen if pool is not active or volume is orphaned
            echo "Warning: Pool deletion failed, removing file manually..."
            rm -f ${qcow2_overlay_path}
        fi
    fi

    # Delete cloud-init ISO file if it exists
    if [[ -n "${cidata_iso_path_local}" ]]; then
        echo "Removing cloud-init ISO: $(basename ${cidata_iso_path_local})"
        rm -f ${cidata_iso_path_local}
    fi

    # Remove XML configuration file
    rm -f ${WORKDIR_PATH}/${domain_to_destroy}.xml

    echo "Domain ${domain_to_destroy} destroyed successfully."
}

################################################################################
# FUNCTION: clean_all
#
# Deletes all Trust Domains and orphaned overlay volumes
#
# DESCRIPTION:
#   1. Finds all domains with DOMAIN_PREFIX
#   2. Destroys each domain using destroy()
#   3. Removes all XML files
#   4. Scans for and removes orphaned overlay volumes
#
# GLOBALS USED:
#   DOMAIN_PREFIX - Prefix for filtering domains
#   STORAGE_POOL_NAME - Pool containing volumes
#   WORKDIR_PATH - Directory containing XML files
#
# SIDE EFFECTS:
#   - Destroys all matching domains
#   - Deletes all XML files
#   - Removes orphaned overlays
#
# NOTES:
#   - Only affects domains with DOMAIN_PREFIX
#   - Does NOT delete base images (only overlays)
################################################################################
clean_all() {
    echo "Cleaning all ${DOMAIN_PREFIX} domains..."

    # Find all domains (running and stopped) with our prefix
    # virsh list --all --name: Lists all domain names
    # grep ${DOMAIN_PREFIX}: Filters to our domains only
    for domain_to_clean in $(virsh list --all --name | grep ${DOMAIN_PREFIX}); do
        # Destroy each domain using the destroy() function
        # This ensures graceful shutdown and proper cleanup
        destroy ${domain_to_clean}
    done

    # Remove all XML configuration files for our domains
    # Glob pattern: ${DOMAIN_PREFIX}*.xml
    rm -f ${WORKDIR_PATH}/${DOMAIN_PREFIX}*.xml

    # Scan for orphaned overlay volumes
    # Orphans occur when:
    #   - Script crashes before cleanup
    #   - Manual domain deletion
    #   - File system operations outside libvirt
    echo "Checking for orphaned overlay volumes..."

    # List all volumes in pool, filter for overlays
    for vol in $(virsh vol-list ${STORAGE_POOL_NAME} 2>/dev/null | awk '/overlay\.[A-Za-z0-9]+\.qcow2/ {print $1}'); do
        # Assume orphaned unless found in use
        # Note: This aggressive approach removes ALL overlays
        # In a cleaner implementation, we'd check each domain's XML
        echo "Found orphaned overlay: ${vol}, removing..."
        virsh vol-delete --pool ${STORAGE_POOL_NAME} ${vol} &>/dev/null
    done

    echo "Cleanup complete."
}

################################################################################
# FUNCTION: print_all
#
# Lists all VMs with rich connection information
#
# DESCRIPTION:
#   Extends basic virsh list with:
#   - IP address (for direct access)
#   - SSH host forward port (for localhost SSH)
#   - vSOCK CID (for vsock communication)
#
# OUTPUT FORMAT:
#   Id Name                    State    (ip:X.X.X.X, hostfwd:PORT, cid:CID)
#
# GLOBALS USED:
#   DOMAIN_PREFIX - For filtering TD domains
#
# SIDE EFFECTS:
#   - Queries QEMU monitor for connection details
#   - Queries libvirt for IP addresses
#
# NOTES:
#   - Only shows extra info for domains matching DOMAIN_PREFIX
#   - "unknown" displayed if information unavailable
################################################################################
print_all() {
    # Read each line from virsh list --all output
    while read -r line
    do
        local extra_info=""

        # Extract domain name if line contains one of our TDs
        # Uses Perl regex to match domain names starting with DOMAIN_PREFIX
        local td_domain=$(echo $line | grep -oP "${DOMAIN_PREFIX}-[^ ]+")

        # If this is one of our TDs, gather connection info
        if [ ! -z "$td_domain" ]; then
            # Query QEMU monitor for SSH port forwarding info
            # HMP (Human Monitor Protocol) command: info usernet
            # Looks for HOST_FORWARD entries
            # Extract field 4 (port number)
            host_port=$(
                virsh \
                    qemu-monitor-command ${td_domain} \
                    --hmp info usernet 2>&1 |
                    awk '/HOST_FORWARD/ {print $4}'
                     )

            # Query QEMU device tree for vSOCK CID
            # HMP command: info qtree
            # Looks for guest-cid property
            # Extract field 3 (CID number)
            guest_cid=$(
                virsh \
                    qemu-monitor-command ${td_domain} \
                    --hmp info qtree 2>&1 |
                    awk '/guest-cid/ {print $3}'
                     )

            # Query libvirt for guest IP address
            # domifaddr returns interface addresses
            # Look for vnet interface
            # Extract field 4 (IP/CIDR)
            host_ip=$(
               virsh domifaddr ${td_domain} 2>&1 |
                    awk '/vnet/ {print $4}'
                     )

            # Check if IP extraction succeeded
            # IP should be in CIDR format (contains /)
            if [[ "${host_ip}" != */* ]]; then
                host_ip="unknown"
            else
                # Strip CIDR suffix to get just IP
                # Example: 192.168.122.45/24 -> 192.168.122.45
                host_ip="${host_ip%/*}"
            fi

            # Construct connection info string
            extra_info="(ip:${host_ip}, hostfwd:$host_port, cid:${guest_cid})"
        fi

        # Print original line plus connection info
        echo "$line $extra_info"
    done < <(virsh "list --all")
}

################################################################################
# FUNCTION: run_td
#
# Main orchestration function for creating a new Trust Domain
#
# DESCRIPTION:
#   Coordinates all steps of TD creation:
#   1. Ensure storage pool exists
#   2. Import base image to pool
#   3. Setup GPUs (if specified)
#   4. Validate input paths
#   5. Create overlay volume
#   6. Generate domain XML
#   7. Boot VM
#   8. Display information
#
# GLOBALS USED:
#   base_img_path - Path to base image
#   xml_template_path - Path to XML template
#   gpus - GPU BDF list (if specified)
#   created_domain - Set by boot_vm()
#
# SIDE EFFECTS:
#   - Creates storage pool (if needed)
#   - Imports base image (if needed)
#   - Prepares GPUs (if specified)
#   - Creates overlay volume
#   - Generates XML
#   - Starts VM
################################################################################
run_td() {
    # Validate user configuration
    if [ -z "${guest_user}" ]; then
        echo "ERROR: --user is required to specify the guest username"
        usage
        exit 1
    fi

    if [ -z "${ssh_key_path}" ] && [ -z "${guest_password}" ]; then
        echo "ERROR: At least one authentication method required: --ssh-key or --password"
        echo "       Recommended: --ssh-key /path/to/public_key.pub"
        exit 1
    fi

    echo "Create and run new virsh domain from ${base_img_path} and ${xml_template_path}"
    echo "  User: ${guest_user}"
    echo "  Hostname: ${guest_hostname}"
    echo "---"

    # Step 1: Ensure storage pool exists and is active
    # This is idempotent - safe to call multiple times
    ensure_storage_pool

    # Step 2: Import base image to pool if not already present
    # Returns early if image already exists in pool
    import_base_image_to_pool

    # Step 3: Generate cloud-init ISO with user configuration
    # This creates an ISO with user-specific settings for runtime injection
    generate_cidata_iso

    # Step 4: Attach GPUs if specified via -g flag
    # This prepares GPUs and generates XML
    # No-op if gpus variable is empty
    attach_gpus ${gpus}

    # Step 5: Validate that all required files exist
    # Exits with error if validation fails
    check_input_paths

    # Step 6: Create overlay volume in storage pool
    # Sets overlay_image_path and overlay_image_name globals
    create_overlay_image

    # Step 7: Generate domain XML from template
    # Performs variable substitution
    create_domain_xml

    # Step 8: Define, rename, and start the VM
    # Sets created_domain global
    boot_vm

    echo "---"
    echo "Domain created successfully!"

    # Display detailed domain information
    # Shows: ID, Name, UUID, OS Type, State, CPUs, Memory
    virsh dominfo "${created_domain}"
}

################################################################################
# FUNCTION: parse_params
#
# Main command-line argument parser
#
# DESCRIPTION:
#   Parses all commands and options:
#   - new: Create new TD
#   - list: List all TDs
#   - delete: Delete TD(s)
#   - pool-info: Show pool information
#   - pool-cleanup: Clean orphaned volumes
#   - *: Pass to virsh (passthrough)
#
# PARAMETERS:
#   $@ - All command-line arguments
#
# EXIT CODES:
#   0 on success
#   1 on invalid options or errors
#
# SIDE EFFECTS:
#   - Sets global variables (base_img_path, xml_template_path, gpus)
#   - Calls appropriate handler functions
#   - May exit script
################################################################################
parse_params() {
    # Infinite loop - processes arguments until break or exit
    while :; do
        # Switch on first argument
        case "${1-}" in
        "" | -h | --help)
            # No arguments or help requested
            usage
            exit 0
            ;;
        new)
            # Create new TD command
            shift  # Move past "new"

            # Parse options for "new" command
            while :; do
                case "${1-}" in
                    -i | --td-image)
                        # Custom base image specified
                        base_img="${2-}"
                        shift 2
                        ;;
                    -t | --xml-template)
                        # Custom XML template specified
                        xml_template="${2-}"
                        shift 2
                        ;;
                    -u | --user)
                        # Guest username specified
                        guest_user="${2-}"
                        shift 2
                        ;;
                    -k | --ssh-key)
                        # SSH public key file specified
                        ssh_key_path="${2-}"
                        shift 2
                        ;;
                    -p | --password)
                        # Guest password specified
                        guest_password="${2-}"
                        shift 2
                        ;;
                    -n | --hostname)
                        # Guest hostname specified
                        guest_hostname="${2-}"
                        shift 2
                        ;;
                    --pool)
                        # Storage pool name specified
                        STORAGE_POOL_NAME="${2-}"
                        shift 2
                        ;;
                    -g | --gpus)
                        # GPU BDF list specified
                        gpus="${2-}"
                        shift 2
                        ;;
                    "")
                        # No more options for "new"
                        break
                        ;;
                    *)
                        # Unknown option
                        echo "${SCRIPT_NAME}: unrecognized option '${1-}'. See '${SCRIPT_NAME} -h'."
                        exit 1
                        ;;
                esac
            done

            # Resolve custom paths to absolute paths (if provided)
            [ -n "${base_img}" ] && base_img_path=$(realpath "${base_img}")
            [ -n "${xml_template}" ] && xml_template_path=$(realpath "${xml_template}")

            # Execute TD creation
            run_td
            exit 0
            ;;
        list)
            # List all VMs with connection info
            print_all
            exit 0
            ;;
        pool-info)
            # Show storage pool information
            # First ensure pool exists/is active
            ensure_storage_pool

            echo "=== Storage Pool Information ==="
            # Display pool details (name, state, capacity, etc.)
            virsh pool-info ${STORAGE_POOL_NAME}
            echo ""

            echo "=== Available Volumes ==="
            # List all volumes in pool (base images + overlays)
            virsh vol-list ${STORAGE_POOL_NAME}
            exit 0
            ;;
        pool-cleanup)
            # Clean up orphaned overlay volumes
            ensure_storage_pool

            echo "Scanning for orphaned overlay volumes..."
            orphan_count=0

            # List all overlay volumes in pool
            for vol in $(virsh vol-list ${STORAGE_POOL_NAME} 2>/dev/null | awk '/overlay\.[A-Za-z0-9]+\.qcow2/ {print $1}'); do
                # Check if any domain is using this overlay
                in_use=false

                # Check all domains (running and stopped)
                for domain in $(virsh list --all --name); do
                    # Search domain XML for reference to this volume
                    if virsh dumpxml ${domain} 2>/dev/null | grep -q "${vol}"; then
                        in_use=true
                        break
                    fi
                done

                # If not in use, delete it
                if [ "$in_use" = false ]; then
                    echo "Found orphaned overlay: ${vol}, removing..."
                    virsh vol-delete --pool ${STORAGE_POOL_NAME} ${vol}
                    ((orphan_count++))
                fi
            done

            echo "Removed ${orphan_count} orphaned overlay volume(s)."
            exit 0
            ;;
        delete)
            # Delete TD(s)
            domain_to_clean="${2-}"

            if [ "${domain_to_clean}" == "all" ]; then
                # Delete all TDs
                clean_all
            else
                # Delete specific TD
                # Validate domain name format
                if [[ ! "${domain_to_clean}" =~ ^${DOMAIN_PREFIX}-[^\ ]+$ ]]; then
                    usage
                    exit 0
                fi
                destroy ${domain_to_clean}
            fi
            exit 0
            ;;
        *)
            # Unknown command - pass to virsh (passthrough feature)
            # This allows using this script as a general virsh wrapper
            # Example: ./tdvirsh console <domain>
            # Becomes: virsh console <domain>
            exec virsh "$@"
            ;;
        esac
        shift
    done
}

################################################################################
# MAIN ENTRY POINT
################################################################################

# Parse command-line arguments and execute appropriate command
parse_params "$@"
